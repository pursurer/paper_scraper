"""
PDF å…ƒæ•°æ®æå–æ¨¡å—

ä» PDF æ–‡ä»¶ä¸­æå–è®ºæ–‡çš„ abstractã€keywords ç­‰å…ƒæ•°æ®ã€‚
ä¸»è¦ç”¨äº AAMAS ç­‰éœ€è¦ä» PDF è·å–ä¿¡æ¯çš„ä¼šè®®ã€‚
"""

import os
import re
import csv
from typing import Dict, List, Optional, Tuple, Any

from .utils import to_csv

# å°è¯•å¯¼å…¥ PDF åº“
_PDF_LIBRARY = None
try:
    import fitz  # PyMuPDF
    _PDF_LIBRARY = 'pymupdf'
except ImportError:
    try:
        from pdfminer.high_level import extract_text as pdfminer_extract
        _PDF_LIBRARY = 'pdfminer'
    except ImportError:
        pass


def get_pdf_library() -> Optional[str]:
    """è·å–å½“å‰å¯ç”¨çš„ PDF åº“ã€‚"""
    return _PDF_LIBRARY


def is_pdf_available() -> bool:
    """æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ PDF åº“ã€‚"""
    return _PDF_LIBRARY is not None


# ============ æ–‡æœ¬æå– ============

def extract_text_from_pdf(pdf_path: str) -> str:
    """
    ä» PDF æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹ã€‚
    
    Args:
        pdf_path: PDF æ–‡ä»¶è·¯å¾„
        
    Returns:
        æå–çš„æ–‡æœ¬å†…å®¹ï¼Œå¤±è´¥è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    if not is_pdf_available():
        return ''
    
    if not os.path.exists(pdf_path):
        return ''
    
    try:
        if _PDF_LIBRARY == 'pymupdf':
            import fitz
            doc = fitz.open(pdf_path)
            text = ""
            for page in doc:
                text += page.get_text()
            doc.close()
            return text
        elif _PDF_LIBRARY == 'pdfminer':
            from pdfminer.high_level import extract_text as pdfminer_extract
            return pdfminer_extract(pdf_path)
    except Exception:
        pass
    
    return ''


# ============ Abstract æå– ============

# Abstract åŒ¹é…æ¨¡å¼
ABSTRACT_PATTERNS = [
    r'Abstract\s*\n\s*([^\n]+(?:\n(?!\s*(?:Keywords?|Introduction|1\.|I\.|Â§))[^\n]+)*)',
    r'ABSTRACT\s*\n\s*([^\n]+(?:\n(?!\s*(?:Keywords?|Introduction|1\.|I\.|Â§))[^\n]+)*)',
    r'Abstract\.?\s*\n\s*([^\n]+(?:\n(?!\s*(?:Keywords?|Introduction|1\.|I\.|Â§))[^\n]+)*)',
]


def extract_abstract(text: str, max_length: int = 2000) -> Optional[str]:
    """
    ä»æ–‡æœ¬ä¸­æå– abstractã€‚
    
    Args:
        text: PDF æå–çš„æ–‡æœ¬
        max_length: æœ€å¤§é•¿åº¦é™åˆ¶
        
    Returns:
        æå–çš„ abstractï¼Œå¤±è´¥è¿”å› None
    """
    if not text:
        return None
    
    for pattern in ABSTRACT_PATTERNS:
        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE | re.DOTALL)
        if match:
            abstract = match.group(1).strip()
            # æ¸…ç†ï¼šç§»é™¤å¤šä½™ç©ºç™½
            abstract = re.sub(r'\s+', ' ', abstract)
            # å¦‚æœå¤ªé•¿ï¼Œæˆªæ–­åˆ°å‰å‡ å¥
            if len(abstract) > max_length:
                sentences = abstract.split('.')
                abstract = '. '.join(sentences[:5])
            return abstract[:max_length]
    
    return None


# ============ Keywords æå– ============

# Keywords åŒ¹é…æ¨¡å¼
KEYWORDS_PATTERNS = [
    r'Keywords?[:\s]+\n?\s*([^\n]+(?:\n(?!\s*(?:Introduction|1\.|I\.|Â§|Abstract))[^\n]+)*)',
    r'KEYWORDS?[:\s]+\n?\s*([^\n]+(?:\n(?!\s*(?:Introduction|1\.|I\.|Â§|Abstract))[^\n]+)*)',
]


def extract_keywords(text: str, max_length: int = 500) -> Optional[str]:
    """
    ä»æ–‡æœ¬ä¸­æå– keywordsã€‚
    
    Args:
        text: PDF æå–çš„æ–‡æœ¬
        max_length: æœ€å¤§é•¿åº¦é™åˆ¶
        
    Returns:
        æå–çš„ keywordsï¼Œå¤±è´¥è¿”å› None
    """
    if not text:
        return None
    
    for pattern in KEYWORDS_PATTERNS:
        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE | re.DOTALL)
        if match:
            keywords = match.group(1).strip()
            # æ¸…ç†ï¼šç§»é™¤å¤šä½™ç©ºç™½
            keywords = re.sub(r'\s+', ' ', keywords)
            # å¦‚æœå¤ªé•¿ï¼Œæˆªæ–­åˆ°ç¬¬ä¸€ä¸ªåˆ†éš”ç¬¦
            if len(keywords) > max_length:
                for sep in [';', '.', '\n']:
                    if sep in keywords:
                        keywords = keywords.split(sep)[0]
                        break
            return keywords[:max_length]
    
    return None


# ============ æ ‡é¢˜æå– ============

def extract_title(text: str, max_length: int = 300) -> Optional[str]:
    """
    ä»æ–‡æœ¬ä¸­æå–è®ºæ–‡æ ‡é¢˜ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€è¡Œæˆ–å‰å‡ è¡Œï¼‰ã€‚
    
    Args:
        text: PDF æå–çš„æ–‡æœ¬
        max_length: æœ€å¤§é•¿åº¦é™åˆ¶
        
    Returns:
        æå–çš„æ ‡é¢˜ï¼Œå¤±è´¥è¿”å› None
    """
    if not text:
        return None
    
    # å–å‰å‡ è¡Œï¼Œå°è¯•æ‰¾åˆ°æ ‡é¢˜
    lines = text.strip().split('\n')
    
    # è·³è¿‡ç©ºè¡Œå’ŒçŸ­è¡Œ
    for line in lines[:10]:
        line = line.strip()
        # è·³è¿‡ç©ºè¡Œã€å¤ªçŸ­æˆ–å¤ªé•¿çš„è¡Œ
        if len(line) < 5 or len(line) > max_length:
            continue
        # è·³è¿‡æ˜æ˜¾ä¸æ˜¯æ ‡é¢˜çš„è¡Œï¼ˆå¦‚ä½œè€…ã€æœºæ„ç­‰ï¼‰
        if '@' in line or 'University' in line or 'Institute' in line:
            continue
        # è·³è¿‡é¡µç ã€æ—¥æœŸç­‰
        if re.match(r'^\d+$', line) or re.match(r'^\d{4}[-/]\d{1,2}', line):
            continue
        return line
    
    return None


# ============ PDF å¤„ç† ============

def process_pdf(pdf_path: str) -> Dict[str, Optional[str]]:
    """
    å¤„ç†å•ä¸ª PDF æ–‡ä»¶ï¼Œæå–æ‰€æœ‰å…ƒæ•°æ®ã€‚
    
    Args:
        pdf_path: PDF æ–‡ä»¶è·¯å¾„
        
    Returns:
        åŒ…å« title, abstract, keywords çš„å­—å…¸
    """
    text = extract_text_from_pdf(pdf_path)
    
    return {
        'title': extract_title(text),
        'abstract': extract_abstract(text),
        'keywords': extract_keywords(text),
    }


def process_pdf_directory(
    pdf_dir: str,
    output_path: Optional[str] = None,
    verbose: bool = True
) -> List[Dict[str, Any]]:
    """
    å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰ PDF æ–‡ä»¶ã€‚
    
    Args:
        pdf_dir: PDF æ–‡ä»¶ç›®å½•
        output_path: è¾“å‡º CSV è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        verbose: æ˜¯å¦æ‰“å°æ—¥å¿—
        
    Returns:
        æå–çš„è®ºæ–‡åˆ—è¡¨
    """
    if not os.path.isdir(pdf_dir):
        if verbose:
            print(f"   âŒ ç›®å½•ä¸å­˜åœ¨: {pdf_dir}")
        return []
    
    if not is_pdf_available():
        if verbose:
            print("   âŒ æœªå®‰è£… PDF åº“ï¼Œè¯·å®‰è£…: pip install PyMuPDF")
        return []
    
    # è·å–æ‰€æœ‰ PDF æ–‡ä»¶
    pdf_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith('.pdf')]
    pdf_files.sort()
    
    if verbose:
        print(f"\nğŸ” å¤„ç† PDF ç›®å½•: {pdf_dir}")
        print(f"   æ‰¾åˆ° {len(pdf_files)} ä¸ª PDF æ–‡ä»¶")
    
    papers = []
    for idx, pdf_file in enumerate(pdf_files):
        pdf_path = os.path.join(pdf_dir, pdf_file)
        
        if verbose:
            print(f"   [{idx+1}/{len(pdf_files)}] {pdf_file[:50]}...")
        
        metadata = process_pdf(pdf_path)
        
        papers.append({
            'title': metadata['title'] or os.path.splitext(pdf_file)[0],
            'abstract': metadata['abstract'] or '',
            'keywords': metadata['keywords'] or '',
            'pdf_path': pdf_path,
            'pdf_file': pdf_file,
        })
    
    if verbose:
        with_abstract = sum(1 for p in papers if p['abstract'])
        with_keywords = sum(1 for p in papers if p['keywords'])
        print(f"\n   âœ… å¤„ç†å®Œæˆ!")
        print(f"      æˆåŠŸæå– abstract: {with_abstract}/{len(papers)}")
        print(f"      æˆåŠŸæå– keywords: {with_keywords}/{len(papers)}")
    
    if output_path and papers:
        _save_extracted_csv(papers, output_path, verbose)
    
    return papers


# ============ AAMAS ä¸“ç”¨ ============

def extract_aamas_metadata(
    pdf_dir: str,
    year: int,
    output_path: Optional[str] = None,
    verbose: bool = True
) -> List[Dict[str, Any]]:
    """
    ä» AAMAS PDF ç›®å½•æå–è®ºæ–‡å…ƒæ•°æ®ã€‚
    
    Args:
        pdf_dir: åŒ…å« AAMAS PDF çš„ç›®å½•
        year: ä¼šè®®å¹´ä»½
        output_path: è¾“å‡º CSV è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        verbose: æ˜¯å¦æ‰“å°æ—¥å¿—
        
    Returns:
        è®ºæ–‡åˆ—è¡¨
        
    Example:
        >>> papers = extract_aamas_metadata('./aamas2025/', 2025)
    """
    if verbose:
        print(f"\nğŸ” æå– AAMAS {year} è®ºæ–‡å…ƒæ•°æ®...")
    
    papers = process_pdf_directory(pdf_dir, verbose=verbose)
    
    # æ·»åŠ  AAMAS ç‰¹å®šå­—æ®µ
    for idx, paper in enumerate(papers):
        paper['conference'] = 'AAMAS'
        paper['year'] = str(year)
        paper['id'] = f"AAMAS_{year}_{idx+1:04d}"
        paper['group'] = ''
    
    if output_path and papers:
        _save_aamas_csv(papers, output_path, verbose)
    
    return papers


def _save_extracted_csv(
    papers: List[Dict[str, Any]],
    output_path: str,
    verbose: bool = True
) -> None:
    """ä¿å­˜æå–çš„è®ºæ–‡åˆ° CSVã€‚"""
    if not papers:
        return
    
    os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
    
    fieldnames = ['title', 'abstract', 'keywords', 'pdf_file', 'pdf_path']
    
    with open(output_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for paper in papers:
            row = {k: paper.get(k, '') for k in fieldnames}
            writer.writerow(row)
    
    if verbose:
        print(f"   ğŸ’¾ å·²ä¿å­˜åˆ° {output_path}")


def _save_aamas_csv(
    papers: List[Dict[str, Any]],
    output_path: str,
    verbose: bool = True
) -> None:
    """ä¿å­˜ AAMAS è®ºæ–‡åˆ°ç»Ÿä¸€æ ¼å¼ CSVã€‚"""
    if not papers:
        return
    
    # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
    papers_for_csv = []
    for paper in papers:
        papers_for_csv.append({
            'id': paper.get('id', ''),
            'title': paper.get('title', ''),
            'keywords': paper.get('keywords', ''),
            'abstract': paper.get('abstract', ''),
            'pdf': paper.get('pdf_path', ''),
            'forum': '',
            'year': paper.get('year', ''),
            'group': paper.get('group', ''),
            'conference': paper.get('conference', 'AAMAS'),
        })
    
    to_csv(papers_for_csv, output_path)
    
    if verbose:
        print(f"   ğŸ’¾ å·²ä¿å­˜åˆ° {output_path}")


# ============ ä»ç´¢å¼•æ–‡ä»¶å¤„ç† ============

def process_from_index(
    index_file: str,
    pdf_column: str = 'pdf_local_path',
    output_path: Optional[str] = None,
    verbose: bool = True
) -> List[Dict[str, Any]]:
    """
    ä»ç´¢å¼• CSV æ–‡ä»¶è¯»å– PDF è·¯å¾„å¹¶æå–å…ƒæ•°æ®ã€‚
    
    Args:
        index_file: ç´¢å¼• CSV æ–‡ä»¶è·¯å¾„
        pdf_column: PDF è·¯å¾„æ‰€åœ¨çš„åˆ—å
        output_path: è¾“å‡º CSV è·¯å¾„
        verbose: æ˜¯å¦æ‰“å°æ—¥å¿—
        
    Returns:
        å¸¦æœ‰å…ƒæ•°æ®çš„è®ºæ–‡åˆ—è¡¨
    """
    if not os.path.exists(index_file):
        if verbose:
            print(f"   âŒ ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_file}")
        return []
    
    if not is_pdf_available():
        if verbose:
            print("   âŒ æœªå®‰è£… PDF åº“ï¼Œè¯·å®‰è£…: pip install PyMuPDF")
        return []
    
    # è¯»å–ç´¢å¼•
    papers = []
    with open(index_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        papers = list(reader)
    
    if verbose:
        print(f"\nğŸ” ä»ç´¢å¼•æ–‡ä»¶å¤„ç†: {index_file}")
        print(f"   æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡")
    
    base_dir = os.path.dirname(index_file)
    
    results = []
    for idx, paper in enumerate(papers):
        pdf_path = paper.get(pdf_column, '')
        
        # å¤„ç†ç›¸å¯¹è·¯å¾„
        if pdf_path and not os.path.isabs(pdf_path):
            pdf_path = os.path.join(base_dir, pdf_path)
        
        if verbose:
            title = paper.get('title', pdf_path)[:50]
            print(f"   [{idx+1}/{len(papers)}] {title}...")
        
        metadata = process_pdf(pdf_path) if pdf_path else {}
        
        result = paper.copy()
        result['abstract'] = metadata.get('abstract') or paper.get('abstract', '')
        result['keywords'] = metadata.get('keywords') or paper.get('keywords', '')
        results.append(result)
    
    if verbose:
        with_abstract = sum(1 for r in results if r.get('abstract'))
        with_keywords = sum(1 for r in results if r.get('keywords'))
        print(f"\n   âœ… å¤„ç†å®Œæˆ!")
        print(f"      æˆåŠŸæå– abstract: {with_abstract}/{len(results)}")
        print(f"      æˆåŠŸæå– keywords: {with_keywords}/{len(results)}")
    
    if output_path:
        _save_extracted_csv(results, output_path, verbose)
    
    return results

