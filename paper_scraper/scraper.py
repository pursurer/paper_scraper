"""
Scraper ‰∏ªÁ±ªÊ®°Âùó

ÂçèË∞É venue ÂèëÁé∞„ÄÅËÆ∫ÊñáËé∑Âèñ„ÄÅËøáÊª§„ÄÅÊèêÂèñÁöÑÂÆåÊï¥Â∑•‰ΩúÊµÅ„ÄÇ
ËøôÊòØ paper_scraper ÂåÖÁöÑÊ†∏ÂøÉÂÖ•Âè£Á±ª„ÄÇ
"""

from typing import List, Dict, Any, Optional, Callable, Tuple

from .utils import get_client, to_csv, papers_to_list
from .venue import get_venues, group_venues
from .paper import get_papers, flatten_papers
from .filters import satisfies_any_filters
from .extractor import Extractor


class Scraper:
    """
    ËÆ∫ÊñáÊäìÂèñÂô®‰∏ªÁ±ª„ÄÇ
    
    ÂçèË∞É‰ª•‰∏ãÊµÅÁ®ãÔºö
    1. ‰ªé OpenReview API Ëé∑Âèñ venues
    2. Ëé∑ÂèñÂêÑ venue ÁöÑËÆ∫Êñá
    3. Â∫îÁî®ÂÖ≥ÈîÆËØçËøáÊª§Âô®
    4. ÊèêÂèñÊåáÂÆöÂ≠óÊÆµ
    5. ‰øùÂ≠ò‰∏∫ CSV
    
    Attributes:
        conferences: ‰ºöËÆÆÂêçÁß∞ÂàóË°®
        years: Âπ¥‰ªΩÂàóË°®
        keywords: ÊêúÁ¥¢ÂÖ≥ÈîÆËØçÂàóË°®
        extractor: Â≠óÊÆµÊèêÂèñÂô®
        fpath: ËæìÂá∫Êñá‰ª∂Ë∑ØÂæÑ
        filters: ËøáÊª§Âô®ÂàóË°®
        
    Example:
        >>> from paper_scraper import Scraper, Extractor
        >>> 
        >>> extractor = Extractor(
        ...     fields=['forum'],
        ...     subfields={'content': ['title', 'abstract', 'keywords', 'pdf']}
        ... )
        >>> 
        >>> scraper = Scraper(
        ...     conferences=['ICLR'],
        ...     years=['2024'],
        ...     keywords=['reinforcement learning'],
        ...     extractor=extractor,
        ...     fpath='papers.csv'
        ... )
        >>> 
        >>> # Ê∑ªÂä†ËøáÊª§Âô®
        >>> from paper_scraper import title_filter, abstract_filter
        >>> scraper.add_filter(title_filter)
        >>> scraper.add_filter(abstract_filter)
        >>> 
        >>> # ËøêË°åÊäìÂèñ
        >>> scraper()
    """
    
    def __init__(
        self,
        conferences: List[str],
        years: List[str],
        keywords: List[str],
        extractor: Extractor,
        fpath: str,
        fns: Optional[List[Callable]] = None,
        groups: Optional[List[str]] = None,
        only_accepted: bool = True,
        client: Any = None,
        verbose: bool = True,
        exclude_workshops: bool = True,
    ):
        """
        ÂàùÂßãÂåñ Scraper„ÄÇ
        
        Args:
            conferences: ‰ºöËÆÆÂêçÁß∞ÂàóË°®ÔºåÂ¶Ç ['ICLR', 'ICML']
            years: Âπ¥‰ªΩÂàóË°®ÔºåÂ¶Ç ['2024', '2025']
            keywords: ÊêúÁ¥¢ÂÖ≥ÈîÆËØçÂàóË°®ÔºåÁ©∫ÂàóË°®Ë°®Á§∫Ëé∑ÂèñÊâÄÊúâËÆ∫Êñá
            extractor: Extractor ÂÆû‰æãÔºåÁî®‰∫éÊèêÂèñËÆ∫ÊñáÂ≠óÊÆµ
            fpath: ËæìÂá∫ CSV Êñá‰ª∂Ë∑ØÂæÑ
            fns: Ëá™ÂÆö‰πâÂ§ÑÁêÜÂáΩÊï∞ÂàóË°®ÔºåÊØè‰∏™ÂáΩÊï∞Êé•Êî∂ËÆ∫ÊñáÂØπË±°Âπ∂ËøîÂõû‰øÆÊîπÂêéÁöÑËÆ∫Êñá
            groups: ÂàÜÁªÑ‰æùÊçÆÔºåÈªòËÆ§‰∏∫‰ºöËÆÆÂêçÁß∞
            only_accepted: ÊòØÂê¶Âè™Ëé∑ÂèñÂ∑≤Êé•ÂèóÁöÑËÆ∫ÊñáÔºàÈªòËÆ§ TrueÔºâ
            client: OpenReview API clientÔºàÂèØÈÄâÔºåÈªòËÆ§Ëá™Âä®ÂàõÂª∫Ôºâ
            verbose: ÊòØÂê¶ÊâìÂç∞Êó•ÂøóÔºàÈªòËÆ§ TrueÔºâ
            exclude_workshops: ÊòØÂê¶ÊéíÈô§ WorkshopÔºàÈªòËÆ§ TrueÔºâ
        """
        self.conferences = conferences
        self.years = years
        self.keywords = keywords
        self.extractor = extractor
        self.fpath = fpath
        self.fns = fns or []
        self.groups = groups or conferences  # ÈªòËÆ§Êåâ‰ºöËÆÆÂàÜÁªÑ
        self.only_accepted = only_accepted
        self.verbose = verbose
        self.exclude_workshops = exclude_workshops
        
        # ËøáÊª§Âô®ÂàóË°®Ôºö[(filter_func, args, kwargs), ...]
        self.filters: List[Tuple[Callable, tuple, dict]] = []
        
        # API clientÔºàÂª∂ËøüÂàùÂßãÂåñÔºâ
        self._client = client
        
        # Â≠òÂÇ®ÊäìÂèñÁªìÊûú
        self.raw_papers: Optional[Dict] = None
        self.filtered_papers: Optional[Dict] = None
    
    @property
    def client(self) -> Any:
        """Âª∂ËøüËé∑Âèñ API client„ÄÇ"""
        if self._client is None:
            self._client = get_client()
        return self._client
    
    def __call__(self) -> List[Dict]:
        """ÂèØË∞ÉÁî®Êé•Âè£ÔºåÊâßË°åÊäìÂèñÊµÅÁ®ã„ÄÇ"""
        return self.scrape()
    
    def __repr__(self) -> str:
        return (
            f"Scraper(conferences={self.conferences}, "
            f"years={self.years}, "
            f"keywords={self.keywords[:3]}{'...' if len(self.keywords) > 3 else ''}, "
            f"filters={len(self.filters)})"
        )
    
    def add_filter(
        self,
        filter_func: Callable,
        *args,
        **kwargs
    ) -> 'Scraper':
        """
        Ê∑ªÂä†ËøáÊª§Âô®„ÄÇ
        
        Args:
            filter_func: ËøáÊª§Âô®ÂáΩÊï∞ÔºåÂ¶Ç title_filter, abstract_filter
            *args: ‰º†ÈÄíÁªôËøáÊª§Âô®ÁöÑÈ¢ùÂ§ñ‰ΩçÁΩÆÂèÇÊï∞
            **kwargs: ‰º†ÈÄíÁªôËøáÊª§Âô®ÁöÑÈ¢ùÂ§ñÂÖ≥ÈîÆÂ≠óÂèÇÊï∞
            
        Returns:
            selfÔºåÊîØÊåÅÈìæÂºèË∞ÉÁî®
            
        Example:
            >>> scraper.add_filter(title_filter)
            >>> scraper.add_filter(abstract_filter, threshold=90)
        """
        self.filters.append((filter_func, args, kwargs))
        return self
    
    def clear_filters(self) -> 'Scraper':
        """Ê∏ÖÁ©∫ÊâÄÊúâËøáÊª§Âô®„ÄÇ"""
        self.filters = []
        return self
    
    def scrape(self) -> List[Dict]:
        """
        ÊâßË°åÂÆåÊï¥ÁöÑÊäìÂèñÊµÅÁ®ã„ÄÇ
        
        ÊµÅÁ®ãÔºö
        1. Ëé∑Âèñ venues
        2. Ëé∑ÂèñËÆ∫Êñá
        3. Â∫îÁî®ËøáÊª§Âô®ÂíåÊèêÂèñÂô®
        4. ‰øùÂ≠ò‰∏∫ CSV
        
        Returns:
            ÊèêÂèñÂêéÁöÑËÆ∫ÊñáÂàóË°®ÔºàÂ≠óÂÖ∏Ê†ºÂºèÔºâ
        """
        if self.verbose:
            print("=" * 60)
            print(f"üöÄ Paper Scraper")
            print(f"   ‰ºöËÆÆ: {', '.join(self.conferences)}")
            print(f"   Âπ¥‰ªΩ: {', '.join(self.years)}")
            print(f"   ÂÖ≥ÈîÆËØç: {self.keywords if self.keywords else '(Ëé∑ÂèñÊâÄÊúâËÆ∫Êñá)'}")
            print(f"   ËøáÊª§Âô®: {len(self.filters)} ‰∏™")
            if self.exclude_workshops:
                print("   ÊéíÈô§: Workshops")
            print("=" * 60)
        
        # Step 1: Ëé∑Âèñ venues
        if self.verbose:
            print("\nüìç Step 1: Ëé∑Âèñ venues...")
        venues = get_venues(
            self.client,
            self.conferences,
            self.years,
            verbose=self.verbose,
            exclude_workshops=self.exclude_workshops
        )
        
        if not venues:
            if self.verbose:
                print("‚ùå Êú™ÊâæÂà∞‰ªª‰Ωï venueÔºåÁªàÊ≠¢ÊäìÂèñ")
            return []
        
        # Step 2: Ëé∑ÂèñËÆ∫Êñá
        if self.verbose:
            print(f"\nüìÑ Step 2: Ëé∑ÂèñËÆ∫Êñá...")
        
        grouped_venues = group_venues(venues, self.groups)
        self.raw_papers = get_papers(
            self.client,
            grouped_venues,
            only_accepted=self.only_accepted,
            verbose=self.verbose
        )
        
        # Step 3: Â∫îÁî®ËøáÊª§Âô®ÂíåÊèêÂèñÂô®
        if self.verbose:
            print(f"\nüîç Step 3: Â∫îÁî®ËøáÊª§Âô®...")
        
        self.filtered_papers = self._apply_on_papers(self.raw_papers)
        
        # Step 4: ËΩ¨Êç¢‰∏∫ÂàóË°®
        papers_list = papers_to_list(self.filtered_papers)
        
        if self.verbose:
            print(f"\nüìä ÁªìÊûú: {len(papers_list)} ÁØáËÆ∫ÊñáÂåπÈÖç")
        
        # Step 5: ‰øùÂ≠ò CSV
        if self.fpath:
            # Á°Æ‰øùÁõÆÂΩïÂ≠òÂú®
            import os
            os.makedirs(os.path.dirname(self.fpath) or '.', exist_ok=True)
            
            if self.verbose:
                print(f"\nüíæ Step 4: ‰øùÂ≠òÂà∞ {self.fpath}...")
            to_csv(papers_list, self.fpath)
            if self.verbose:
                print(f"‚úÖ Â∑≤‰øùÂ≠òÂà∞ {self.fpath}")
        
        if self.verbose:
            print("\n" + "=" * 60)
            print("üéâ ÊäìÂèñÂÆåÊàê!")
            print("=" * 60)
        
        return papers_list
    
    def _apply_on_papers(self, papers: Dict) -> Dict:
        """
        ÂØπËÆ∫ÊñáÂ∫îÁî®ËøáÊª§Âô®„ÄÅËá™ÂÆö‰πâÂáΩÊï∞ÂíåÊèêÂèñÂô®„ÄÇ
        
        Args:
            papers: ÂµåÂ•óÁöÑËÆ∫ÊñáÂ≠óÂÖ∏ {group: {venue: [papers]}}
            
        Returns:
            Â§ÑÁêÜÂêéÁöÑËÆ∫ÊñáÂ≠óÂÖ∏ÔºàÂêåÊ†∑ÁªìÊûÑÔºå‰ΩÜËÆ∫ÊñáÂ∑≤ËΩ¨‰∏∫Â≠óÂÖ∏Ê†ºÂºèÔºâ
        """
        modified_papers = {}
        total_matched = 0
        
        for group, grouped_venues in papers.items():
            modified_papers[group] = {}
            
            for venue, venue_papers in grouped_venues.items():
                modified_papers[group][venue] = []
                
                # Ëß£Êûê venue ‰ø°ÊÅØ
                venue_info = self._parse_venue(venue)
                
                for paper in venue_papers:
                    # Â∫îÁî®ËøáÊª§Âô®
                    if self.filters and self.keywords:
                        _, _, satisfies = satisfies_any_filters(
                            paper,
                            self.keywords,
                            self.filters
                        )
                        if not satisfies:
                            continue
                    
                    # Ê∑ªÂä†ÂÖÉÊï∞ÊçÆ
                    self._add_metadata(paper, group, venue, venue_info)
                    
                    # ÊâßË°åËá™ÂÆö‰πâÂáΩÊï∞
                    for fn in self.fns:
                        paper = fn(paper)
                    
                    # ÊèêÂèñÂ≠óÊÆµ
                    extracted_paper = self.extractor(paper)
                    
                    # Ê∑ªÂä†Âπ¥‰ªΩ
                    extracted_paper['year'] = venue_info.get('year', '')
                    
                    modified_papers[group][venue].append(extracted_paper)
                    total_matched += 1
        
        if self.verbose:
            print(f"   ‚úÖ ÂåπÈÖç {total_matched} ÁØáËÆ∫Êñá")
        
        return modified_papers
    
    def _parse_venue(self, venue: str) -> Dict[str, str]:
        """
        Ëß£Êûê venue IDÔºåÊèêÂèñÁªÑÁªá„ÄÅÂπ¥‰ªΩ„ÄÅÁ±ªÂûã‰ø°ÊÅØ„ÄÇ
        
        Args:
            venue: venue IDÔºåÂ¶Ç 'ICLR.cc/2024/Conference'
            
        Returns:
            ÂåÖÂê´ org, year, type ÁöÑÂ≠óÂÖ∏
        """
        parts = venue.split('/')
        
        info = {
            'org': parts[0] if len(parts) > 0 else '',
            'year': '',
            'type': parts[-1] if len(parts) > 1 else '',
        }
        
        # ÊâæÂà∞Âπ¥‰ªΩ
        for part in parts:
            if part.isdigit() and len(part) == 4:
                info['year'] = part
                break
        
        return info
    
    def _add_metadata(
        self,
        paper: Any,
        group: str,
        venue: str,
        venue_info: Dict[str, str]
    ) -> None:
        """
        ÂêëËÆ∫ÊñáÊ∑ªÂä†ÂÖÉÊï∞ÊçÆ„ÄÇ
        
        Args:
            paper: ËÆ∫ÊñáÂØπË±°
            group: ÂàÜÁªÑÂêçÁß∞
            venue: venue ID
            venue_info: Ëß£ÊûêÂêéÁöÑ venue ‰ø°ÊÅØ
        """
        # Á°Æ‰øù content Â≠òÂú®
        if not hasattr(paper, 'content'):
            return
        
        if not isinstance(paper.content, dict):
            return
        
        # Ê∑ªÂä†ÂàÜÁªÑ‰ø°ÊÅØ
        paper.content['group'] = group
        
        # Êé®Êñ≠ presentation typeÔºàÂ¶ÇÊûúÊú™ËÆæÁΩÆÔºâ
        presentation_type = paper.content.get('presentation_type')
        if not presentation_type:
            paper.content['presentation_type'] = self._infer_presentation_type(venue)
    
    def _infer_presentation_type(self, venue: str) -> str:
        """
        ‰ªé venue ÂêçÁß∞Êé®Êñ≠ËÆ∫ÊñáÂ±ïÁ§∫Á±ªÂûã„ÄÇ
        
        Args:
            venue: venue ID
            
        Returns:
            Â±ïÁ§∫Á±ªÂûãÔºö'Oral', 'Spotlight', Êàñ 'Poster'
        """
        venue_lower = venue.lower()
        
        if 'oral' in venue_lower and 'spotlight' not in venue_lower:
            return 'Oral'
        elif 'spotlight' in venue_lower:
            return 'Spotlight'
        else:
            return 'Poster'
    
    # ============ ‰æøÊç∑ÊñπÊ≥ï ============
    
    def get_paper_count(self) -> int:
        """Ëé∑ÂèñÂ∑≤ÊäìÂèñÁöÑËÆ∫ÊñáÊÄªÊï∞„ÄÇ"""
        if self.filtered_papers is None:
            return 0
        
        total = 0
        for group_papers in self.filtered_papers.values():
            for venue_papers in group_papers.values():
                total += len(venue_papers)
        return total
    
    def get_papers_flat(self) -> List[Dict]:
        """Ëé∑ÂèñÊâÅÂπ≥ÂåñÁöÑËÆ∫ÊñáÂàóË°®„ÄÇ"""
        if self.filtered_papers is None:
            return []
        return papers_to_list(self.filtered_papers)


def create_scraper(
    conferences: List[str],
    years: List[str],
    keywords: Optional[List[str]] = None,
    output_path: str = 'papers.csv',
    fields: Optional[List[str]] = None,
    subfields: Optional[Dict[str, List[str]]] = None,
    only_accepted: bool = True,
    exclude_workshops: bool = True,
) -> Scraper:
    """
    ‰æøÊç∑ÂáΩÊï∞ÔºöÂàõÂª∫ÈÖçÁΩÆÂ•ΩÁöÑ Scraper ÂÆû‰æã„ÄÇ
    
    Args:
        conferences: ‰ºöËÆÆÂêçÁß∞ÂàóË°®
        years: Âπ¥‰ªΩÂàóË°®
        keywords: ÂÖ≥ÈîÆËØçÂàóË°®ÔºàÂèØÈÄâÔºâ
        output_path: ËæìÂá∫Êñá‰ª∂Ë∑ØÂæÑ
        fields: Ë¶ÅÊèêÂèñÁöÑÈ°∂Â±ÇÂ≠óÊÆµ
        subfields: Ë¶ÅÊèêÂèñÁöÑÂ≠êÂ≠óÊÆµ
        only_accepted: ÊòØÂê¶Âè™Ëé∑ÂèñÂ∑≤Êé•ÂèóËÆ∫Êñá
        exclude_workshops: ÊòØÂê¶ÊéíÈô§ WorkshopÔºàÈªòËÆ§ TrueÔºâ
        
    Returns:
        ÈÖçÁΩÆÂ•ΩÁöÑ Scraper ÂÆû‰æã
        
    Example:
        >>> scraper = create_scraper(
        ...     conferences=['ICLR'],
        ...     years=['2024'],
        ...     keywords=['transformer'],
        ...     output_path='iclr_2024.csv'
        ... )
        >>> scraper.add_filter(title_filter)
        >>> scraper()
    """
    # ÈªòËÆ§Â≠óÊÆµÈÖçÁΩÆ
    if fields is None:
        fields = ['forum']
    
    if subfields is None:
        subfields = {
            'content': ['title', 'abstract', 'keywords', 'pdf', 'presentation_type']
        }
    
    extractor = Extractor(
        fields=fields,
        subfields=subfields,
        include_subfield=False
    )
    
    return Scraper(
        conferences=conferences,
        years=years,
        keywords=keywords or [],
        extractor=extractor,
        fpath=output_path,
        only_accepted=only_accepted,
        exclude_workshops=exclude_workshops,
    )

