"""
å·¥å…·å‡½æ•°æ¨¡å—

æä¾›é€šç”¨çš„å·¥å…·å‡½æ•°ï¼š
- API å®¢æˆ·ç«¯è·å–å’Œé‡è¯•æœºåˆ¶
- CSV å¯¼å‡ºï¼ˆå¸¦å»é‡ã€æ¸…ç†æ¢è¡Œç¬¦ï¼‰
- PKL åºåˆ—åŒ–/ååºåˆ—åŒ–
"""

import csv
import os
import time
import json
from functools import wraps
from typing import List, Dict, Any, Callable, Optional
from datetime import datetime

import dill


# ============ é‡è¯•æœºåˆ¶ ============

def retry_with_backoff(
    max_retries: int = 5,
    initial_delay: float = 1,
    max_delay: float = 60,
    backoff_factor: float = 2
) -> Callable:
    """
    è£…é¥°å™¨ï¼šä¸ºå‡½æ•°æ·»åŠ é‡è¯•æœºåˆ¶å’ŒæŒ‡æ•°é€€é¿ç­–ç•¥ï¼Œç‰¹åˆ«å¤„ç† 429 é”™è¯¯ï¼ˆAPI é™æµï¼‰
    
    Args:
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        initial_delay: åˆå§‹å»¶è¿Ÿï¼ˆç§’ï¼‰
        max_delay: æœ€å¤§å»¶è¿Ÿï¼ˆç§’ï¼‰
        backoff_factor: é€€é¿å› å­ï¼ˆæ¯æ¬¡é‡è¯•å»¶è¿Ÿä¹˜ä»¥è¿™ä¸ªå› å­ï¼‰
        
    Returns:
        è£…é¥°åçš„å‡½æ•°
        
    Example:
        @retry_with_backoff(max_retries=3, initial_delay=2)
        def my_api_call():
            return requests.get(url)
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            delay = initial_delay
            last_exception = None
            
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    error_str = str(e)
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ 429 é”™è¯¯ï¼ˆAPI é™æµï¼‰
                    is_rate_limit = (
                        '429' in error_str or 
                        'Too Many Requests' in error_str or 
                        'rate limit' in error_str.lower()
                    )
                    
                    if attempt < max_retries - 1:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                        if is_rate_limit:
                            # å¯¹äº 429 é”™è¯¯ï¼Œä½¿ç”¨æ›´é•¿çš„å»¶è¿Ÿ
                            wait_time = min(delay * 2, max_delay)
                            print(f"âš ï¸  API é™æµï¼ˆ429 é”™è¯¯ï¼‰ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•... "
                                  f"(å°è¯• {attempt + 1}/{max_retries})")
                        else:
                            wait_time = delay
                            print(f"âš ï¸  è¯·æ±‚å¤±è´¥ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•... "
                                  f"(å°è¯• {attempt + 1}/{max_retries})")
                            print(f"   é”™è¯¯ä¿¡æ¯: {error_str[:100]}")
                        
                        time.sleep(wait_time)
                        delay = min(delay * backoff_factor, max_delay)
                    else:
                        # æœ€åä¸€æ¬¡å°è¯•ä¹Ÿå¤±è´¥äº†
                        print(f"âŒ è¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})")
                        print(f"   æœ€åé”™è¯¯: {error_str}")
                        raise last_exception
            
            # ç†è®ºä¸Šä¸ä¼šåˆ°è¾¾è¿™é‡Œï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§
            if last_exception:
                raise last_exception
                
        return wrapper
    return decorator


def safe_api_call(func: Callable, *args, **kwargs) -> Any:
    """
    å®‰å…¨åœ°è°ƒç”¨ API å‡½æ•°ï¼Œå¸¦é‡è¯•æœºåˆ¶
    
    Args:
        func: è¦è°ƒç”¨çš„å‡½æ•°
        *args, **kwargs: ä¼ é€’ç»™å‡½æ•°çš„å‚æ•°
    
    Returns:
        å‡½æ•°è¿”å›å€¼
        
    Example:
        result = safe_api_call(client.get_all_notes, content={'venueid': venue})
    """
    @retry_with_backoff(max_retries=5, initial_delay=2, max_delay=120)
    def _call():
        return func(*args, **kwargs)
    
    return _call()


# ============ OpenReview API å®¢æˆ·ç«¯ ============

def get_client():
    """
    è·å– OpenReview API v2 å®¢æˆ·ç«¯ã€‚
    ä½¿ç”¨é‡è¯•æœºåˆ¶å¤„ç†ç™»å½•æ—¶çš„ API é™æµã€‚
    
    Returns:
        OpenReview API v2 å®¢æˆ·ç«¯å®ä¾‹
        
    Raises:
        ImportError: å¦‚æœ openreview åŒ…æœªå®‰è£…
        Exception: å¦‚æœç™»å½•å¤±è´¥
    """
    try:
        import openreview
    except ImportError:
        raise ImportError(
            "openreview-py æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install openreview-py"
        )
    
    # ä»æ–°é…ç½®ç³»ç»Ÿè·å–å‡­è¯
    email = None
    password = None
    
    try:
        from config import get_config
        config = get_config()
        email = config.openreview_email
        password = config.openreview_password
    except ImportError:
        pass
    
    # å‘åå…¼å®¹ï¼šå¦‚æœé…ç½®ç³»ç»Ÿæœªè®¾ç½®ï¼Œå°è¯•ç¯å¢ƒå˜é‡
    if not email or not password:
        email = os.environ.get("OPENREVIEW_EMAIL") or email
        password = os.environ.get("OPENREVIEW_PASSWORD") or password
    
    if not email or not password:
        raise ValueError(
            "æœªæ‰¾åˆ° OpenReview å‡­è¯ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENREVIEW_EMAIL å’Œ OPENREVIEW_PASSWORDï¼Œ"
            "æˆ–åˆ›å»º config/config.py æ–‡ä»¶ã€‚"
        )
    
    @retry_with_backoff(max_retries=5, initial_delay=5, max_delay=120, backoff_factor=2)
    def _create_client_v2():
        return openreview.api.OpenReviewClient(
            baseurl='https://api2.openreview.net',
            username=email,
            password=password
        )
    
    print("ğŸ”„ æ­£åœ¨ç™»å½• OpenReview API v2...")
    client = _create_client_v2()
    print("âœ… API v2 ç™»å½•æˆåŠŸ")
    
    return client


# ============ æ•°æ®è½¬æ¢ ============

def papers_to_list(papers: Dict) -> List[Dict]:
    """
    å°†åµŒå¥—çš„è®ºæ–‡å­—å…¸è½¬æ¢ä¸ºæ‰å¹³åˆ—è¡¨ã€‚
    
    Args:
        papers: åµŒå¥—å­—å…¸ï¼Œæ ¼å¼ä¸º {group: {venue: [paper, ...]}}
        
    Returns:
        è®ºæ–‡åˆ—è¡¨
    """
    all_papers = []
    for grouped_venues in papers.values():
        for venue_papers in grouped_venues.values():
            for paper in venue_papers:
                all_papers.append(paper)
    return all_papers


# ============ CSV å¯¼å‡º ============

# é»˜è®¤ CSV å­—æ®µï¼ˆæŒ‰é¡ºåºï¼‰
DEFAULT_CSV_FIELDS = [
    'id', 'title', 'keywords', 'abstract', 
    'pdf', 'forum', 'year', 'presentation_type'
]

# éœ€è¦æ¸…ç†æ¢è¡Œç¬¦çš„æ–‡æœ¬å­—æ®µ
TEXT_FIELDS_TO_CLEAN = ['abstract', 'title', 'keywords']


def _clean_value(value: Any) -> str:
    """
    æ¸…ç†å­—æ®µå€¼ï¼Œç¡®ä¿æ˜¯å­—ç¬¦ä¸²ä¸”æ²¡æœ‰ Noneã€‚
    
    Args:
        value: ä»»æ„ç±»å‹çš„å€¼
        
    Returns:
        æ¸…ç†åçš„å­—ç¬¦ä¸²
    """
    if value is None:
        return ''
    if isinstance(value, (dict, list)):
        try:
            return json.dumps(value, ensure_ascii=False)
        except:
            return str(value)
    return str(value)


def _clean_text_field(value: str) -> str:
    """
    æ¸…ç†æ–‡æœ¬å­—æ®µä¸­çš„æ¢è¡Œç¬¦ã€‚
    
    Args:
        value: æ–‡æœ¬å­—ç¬¦ä¸²
        
    Returns:
        æ¸…ç†åçš„å­—ç¬¦ä¸²ï¼ˆæ¢è¡Œç¬¦æ›¿æ¢ä¸ºç©ºæ ¼ï¼‰
    """
    if not isinstance(value, str):
        return value
    # å°†æ¢è¡Œç¬¦æ›¿æ¢ä¸ºç©ºæ ¼
    cleaned = value.replace('\n', ' ').replace('\r', ' ')
    # å°†å¤šä¸ªè¿ç»­ç©ºæ ¼æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
    while '  ' in cleaned:
        cleaned = cleaned.replace('  ', ' ')
    return cleaned.strip()


def _extract_forum_id(forum: str) -> Optional[str]:
    """
    ä» forum å­—æ®µæå–è®ºæ–‡ IDï¼ˆå¯èƒ½æ˜¯å®Œæ•´ URLï¼‰ã€‚
    
    Args:
        forum: forum å­—æ®µå€¼
        
    Returns:
        æå–çš„ ID æˆ– None
    """
    if not isinstance(forum, str) or not forum.strip():
        return None
    
    # å¦‚æœæ˜¯ URLï¼Œæå– ID éƒ¨åˆ†
    if 'forum?id=' in forum:
        return forum.split('forum?id=')[-1].split('&')[0]
    elif '/' in forum and len(forum) > 20:
        return forum.split('/')[-1].split('?')[0]
    else:
        return forum.strip()


def to_csv(
    papers_list: List[Dict],
    fpath: str,
    fields: List[str] = None,
    append: bool = True
) -> None:
    """
    å°†è®ºæ–‡åˆ—è¡¨å†™å…¥ CSV æ–‡ä»¶ã€‚
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
    - è‡ªåŠ¨å»é‡ï¼ˆåŸºäº forum å­—æ®µæˆ– title+yearï¼‰
    - æ¸…ç†æ¢è¡Œç¬¦å’Œç‰¹æ®Šå­—ç¬¦
    - æ”¯æŒè¿½åŠ æ¨¡å¼ï¼ˆåˆå¹¶ç°æœ‰æ•°æ®ï¼‰
    - è‡ªåŠ¨ç”Ÿæˆå”¯ä¸€ ID
    - UTF-8 BOM ç¼–ç ï¼ˆExcel å‹å¥½ï¼‰
    - æŒ‰å±•ç¤ºç±»å‹æ’åºï¼ˆOral > Spotlight > Posterï¼‰
    
    Args:
        papers_list: è®ºæ–‡å­—å…¸åˆ—è¡¨
        fpath: è¾“å‡º CSV æ–‡ä»¶è·¯å¾„
        fields: è¦ä¿ç•™çš„å­—æ®µåˆ—è¡¨ï¼Œé»˜è®¤ä½¿ç”¨ DEFAULT_CSV_FIELDS
        append: æ˜¯å¦è¿½åŠ åˆ°ç°æœ‰æ–‡ä»¶ï¼ˆé»˜è®¤ Trueï¼‰
    """
    if fields is None:
        fields = DEFAULT_CSV_FIELDS.copy()
    
    # ä»æ–‡ä»¶è·¯å¾„æå–ä¼šè®®åç§°ï¼ˆç”¨äºç”Ÿæˆ IDï¼‰
    filename = os.path.basename(fpath)
    if '_papers.csv' in filename:
        conference_name = filename.replace('_papers.csv', '').lower()
    elif '.csv' in filename:
        conference_name = filename.replace('.csv', '').lower()
    else:
        conference_name = None
    
    # å¦‚æœè®ºæ–‡åˆ—è¡¨ä¸ºç©ºï¼Œåˆ›å»ºå¸¦è¡¨å¤´çš„ç©º CSV æ–‡ä»¶
    if len(papers_list) == 0:
        with open(fpath, 'w', encoding='utf-8-sig', newline='') as fp:
            writer = csv.DictWriter(
                fp,
                fieldnames=fields,
                quoting=csv.QUOTE_MINIMAL,
                doublequote=True,
                lineterminator='\n'
            )
            writer.writeheader()
        print(f"âœ… å·²åˆ›å»ºç©º CSV æ–‡ä»¶ï¼ˆå¸¦è¡¨å¤´ï¼‰: {fpath}")
        return
    
    # è¯»å–ç°æœ‰æ•°æ®ï¼ˆå¦‚æœæ–‡ä»¶å­˜åœ¨ä¸” append=Trueï¼‰
    existing_papers = []
    if append and os.path.exists(fpath):
        try:
            with open(fpath, 'r', encoding='utf-8-sig', newline='') as fp:
                reader = csv.DictReader(fp)
                existing_papers = list(reader)
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è¯»å–ç°æœ‰æ–‡ä»¶ {fpath}ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶: {e}")
            existing_papers = []
    
    # åˆå¹¶æ•°æ®ï¼ˆæ–°æ•°æ®ä¼˜å…ˆï¼‰
    all_papers = papers_list + existing_papers
    
    # å»é‡
    seen_ids = set()
    unique_papers = []
    duplicates_count = 0
    
    for paper in all_papers:
        # æ¸…ç†å­—æ®µå€¼
        cleaned_paper = {}
        for key, value in paper.items():
            cleaned_value = _clean_value(value)
            if key in TEXT_FIELDS_TO_CLEAN:
                cleaned_value = _clean_text_field(cleaned_value)
            cleaned_paper[key] = cleaned_value
        
        # æå–å”¯ä¸€æ ‡è¯†
        forum_id = _extract_forum_id(cleaned_paper.get('forum', ''))
        
        if forum_id:
            unique_id = forum_id
        else:
            # ä½¿ç”¨ title + year ä½œä¸ºå¤‡é€‰æ ‡è¯†
            title = cleaned_paper.get('title', '').strip()
            year = cleaned_paper.get('year', '').strip()
            unique_id = f"{title}|{year}"
        
        if unique_id not in seen_ids:
            seen_ids.add(unique_id)
            unique_papers.append(cleaned_paper)
        else:
            duplicates_count += 1
    
    if duplicates_count > 0:
        print(f"ğŸ“Š å»é‡: ç§»é™¤äº† {duplicates_count} æ¡é‡å¤è®°å½•")
    
    print(f"ğŸ“Š å”¯ä¸€è®ºæ–‡æ•°: {len(unique_papers)}")
    
    # æŒ‰å±•ç¤ºç±»å‹æ’åº
    presentation_priority = {'Oral': 0, 'Spotlight': 1, 'Poster': 2}
    
    def sort_key(paper):
        ptype = paper.get('presentation_type', 'Poster')
        priority = presentation_priority.get(ptype, 3)
        title = paper.get('title', '')
        return (priority, title.lower())
    
    unique_papers.sort(key=sort_key)
    
    # ç”Ÿæˆå”¯ä¸€ ID
    if conference_name:
        for idx, paper in enumerate(unique_papers, start=1):
            paper['id'] = f"{conference_name}_{idx}"
    
    # å†™å…¥ CSV
    with open(fpath, 'w', encoding='utf-8-sig', newline='') as fp:
        writer = csv.DictWriter(
            fp,
            fieldnames=fields,
            quoting=csv.QUOTE_MINIMAL,
            doublequote=True,
            lineterminator='\n'
        )
        writer.writeheader()
        
        for paper in unique_papers:
            row = {field: paper.get(field, '') for field in fields}
            writer.writerow(row)
    
    if conference_name:
        print(f"âœ… å·²ä¸ºè®ºæ–‡æ·»åŠ å”¯ä¸€ IDï¼ˆæ ¼å¼: {conference_name}_åºå·ï¼‰")
    
    print(f"âœ… CSV æ–‡ä»¶å·²ä¿å­˜: {fpath}")


# ============ PKL åºåˆ—åŒ– ============

def save_papers(papers: Any, fpath: str) -> None:
    """
    å°†è®ºæ–‡æ•°æ®ä¿å­˜ä¸º PKL æ–‡ä»¶ã€‚
    
    Args:
        papers: è¦ä¿å­˜çš„è®ºæ–‡æ•°æ®ï¼ˆä»»æ„ Python å¯¹è±¡ï¼‰
        fpath: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    with open(fpath, 'wb') as fp:
        dill.dump(papers, fp)
    print(f"âœ… Papers saved at: {fpath}")


def load_papers(fpath: str) -> Any:
    """
    ä» PKL æ–‡ä»¶åŠ è½½è®ºæ–‡æ•°æ®ã€‚
    
    Args:
        fpath: PKL æ–‡ä»¶è·¯å¾„
        
    Returns:
        åŠ è½½çš„è®ºæ–‡æ•°æ®
    """
    with open(fpath, 'rb') as fp:
        papers = dill.load(fp)
    print(f"âœ… Papers loaded from: {fpath}")
    return papers

